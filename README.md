
Week 2 Project
ETL and EDA Pipeline

في هذا المشروع اشتغلت على بناء بايبلاين كامل لمعالجه البيانات وتحليلها. الهدف كان تطبيق مفاهيم ETL بشكل عملي ثم استخدام البيانات الناتجه في التحليل الاستكشافي ورسم اشكال توضح النتائج.

المشروع يمثل شغل الاسبوع كامل من اول تحميل البيانات الخام الى تجهيز مشروع جاهز للتسليم والتشغيل.

فكره المشروع بشكل عام

بنيت بايبلاين ETL منظم يمر بالمراحل التاليه
تحميل البيانات الخام
تنظيف البيانات والتحقق من جودتها
دمج الجداول بشكل امن
معالجه القيم المتطرفه
انتاج جدول تحليلي نهائي
تسجيل معلومات التشغيل في ملف metadata

بعدها استخدمت البيانات الناتجه في تحليل EDA ورسم اشكال توضح السلوك العام للبيانات.

اعدادات وتشغيل المشروع

اول خطوه هي الدخول على جذر المشروع

بعدها انشات بيئه افتراضيه

python -m venv .venv

ثم تفعيلها

في ويندوز
.venv\Scripts\activate

بعدها ثبت المكتبات المطلوبه

pip install -r requirements.txt

تشغيل ETL

تشغيل بايبلاين ETL يتم عن طريق الامر التالي

python scripts/run_etl.py


مخرجات ETL

بعد تشغيل ETL تطلع الملفات التاليه

data/processed/analytics_table.parquet
هذا الجدول النهائي اللي استخدمته في التحليل

data/processed/orders_clean.parquet
نسخه منظفه من الطلبات

data/processed/users.parquet
نسخه منظفه من المستخدمين

data/processed/_run_meta.json
ملف فيه معلومات عن التشغيل مثل
عدد الصفوف الناتجه
نسبه المطابقه في join
عدد القيم الناقصه في الوقت
والمسارات المستخدمه في التشغيل

تحليل البيانات EDA

بعد تشغيل ETL انتقلت لتحليل البيانات باستخدام الملف

notebooks/eda.ipynb

التحليل يعتمد فقط على البيانات الموجوده في data/processed
وسويت فيه التالي
تحليل الايرادات حسب الدول
تحليل التوجه الزمني الشهري
دراسه توزيع قيم الطلب بعد winsorization
مقارنات باستخدام bootstrap بين مجموعات مختلفه
وتصدير الرسومات الى reports/figures

ملخص الشغل خلال الايام واعتقد هذا المهم لك استاذ:

اليوم الاول
تحميل البيانات وفهم الاعمده وشكل البيانات

اليوم الثاني
تنظيف البيانات ومعالجه القيم الناقصه وتوحيد الانواع

اليوم الثالث
بناء جدول تحليلي وربط الجداول بشكل امن

اليوم الرابع
تحليل البيانات ورسم الاشكال واستخدام bootstrap

اليوم الخامس
تجميع كل الشغل في ETL واحد
اضافه run metadata
كتابه summary و README
وتجهيز المشروع كملف تسليم كامل

ملاحظات على جوده البيانات

حجم البيانات صغير نسبيا
بعض النتائج الاحصائيه غير حاسمه
تم استخدام winsorization لتخفيف تاثير القيم المتطرفه
التحليل يعكس الفتره الزمنيه الموجوده فقط ولا يمثل سلوك طويل المدى

 لتحميل المشروع

اول شي شغل

python -m venv .venv
pip install -r requirements.txt

بعدها شغل

python scripts/run_etl.py

المفروض تشوف
ملفات parquet في data/processed
ملف _run_meta.json
وتقدر بعدها تفتح eda.ipynb ةتشغل التحليل

